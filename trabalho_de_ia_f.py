# -*- coding: utf-8 -*-
"""Trabalho de IA F.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QonYvBkudNaGG9G2_YBe1QLwgVqeN-QU

<hr style="height:10px"> 
 
<div class='container2'>
	<h1>Trabalho acadêmico: Aprendizagem de Máquina - Classificação de Vinhos - CSI457</h1>
    <h2>UFOP - DECSI</h2>
</div>
Aluno:<a href="https://github.com/wolfMatheus/" > Matheus Fernandes Gomes</a> <br> Matricula: 17.2.5941.</br> Professor: Talles Medeiros
<hr style="height:5px"> 
    
<h2>Análise e Preparação dos Dados</h2>

## Introdução

Esse trabalho visa apresentar uma análise estatística, o pré-processamento e, por fim, realizar a tarefa preditiva de classificação usando os algoritmos KNN (K-nearest neighbors, ou “K-vizinhos mais próximos”) e MLP (MultiLayer Perceptron). Ondem serão realizadas tarefas de análise e pré-processamento durante a execução do algoritimo.  A base de dados Wine.csv deverá ser importada para a execução desse algoritimo, ela possui 13 atributos descritivos e 1 atributo meta (3 classes) O algoritmo será treinado com 70% dos dados e 30% foram destinados para teste. O hyperparâmetro K do KNN foi otimizado para obter o melhor K neste problema. A rede MLP também será otimizada para obter o melhor desempenho preditivo. Os resultados serão exibidos junto a uma acurácia sobre o conjunto de teste, Tambem será apresentada a matriz de confusáo para este mesmo conjunto.

---
## Recursos Necessários

Para este *notebook*, deve ser utilizado o `Python 3.5` ou superior com as seguintes bibliotecas externas, que deverão ser instaladas:

* [`matplotlib`](https://matplotlib.org/) (versão 3.1.3 ou superior): construção e exibição de gráficos variados
* [`seaborn`](https://seaborn.pydata.org/) (versão 0.10.0 ou superior): construção e exibição de gráficos variados.
* [`numpy`](https://numpy.org) (versão 1.16.2 ou superior): manipulação de dados em formato de vetores e matrizes.
* [`pandas`](https://pandas.pydata.org/pandas-docs/stable/index.html) (versão 0.24.1 ou superior): manipulação de dados em formato de tabelas.
* [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)(versão 0.24.1 ou superior): Transforme recursos dimensionando cada recurso para um determinado intervalo.
* [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) (versão 0.24.1 ou superior): Pipeline de transformações com um estimador final.
* [`metrics`](https://scikit-learn.org/stable/modules/model_evaluation.html) (versão 0.24.1 ou superior): Verifica as metricas das variaveis
* [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) (versão 0.24.1 ou superior): Calcular a matriz de confusão para avaliar a precisão de uma classificação.
* [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) (versão 0.24.1 ou superior): Padronize recursos removendo a média e dimensionando para a variação da unidade.
* [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) (versão 0.24.1 ou superior): Classificador implementando o voto dos k-vizinhos mais próximos.
* [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) (versão 0.24.1 ou superior): Divida matrizes ou matrizes em subconjuntos aleatórios de treinamento e teste
* [`ListedColormap`](https://matplotlib.org/stable/api/_as_gen/matplotlib.colors.ListedColormap.html) (versão 0.24.1 ou superior): Objeto de mapa de cores gerado a partir de uma lista de cores.
* [`matplotlib.pyplot`](https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html) (versão 0.24.1 ou superior): É uma interface baseada em estado para matplotlib
* [`sklearn`](https://scikit-learn.org/stable/) (versão 0.24.1 ou superior): Aprendizado de máquina de código aberto


Será utilizado também o conjuntos de dados disponibilizado junto com este *notebook*, que se encontra no diretório `datasets`, em formato de arquivo `.csv`.

---
## Carregando os dados

Primeiro, foram importadas todas as bibliotecas que serão usadas ao longo deste notebook.
"""

# -*- coding: utf-8 -*-

import numpy as np # importa a biblioteca usada para trabalhar com vetores e matrizes
import pandas as pd # importa a biblioteca usada para trabalhar com dataframes (dados em formato de tabela) e análise de dados

# bibliotecas usadas para geracao de graficos
import seaborn as sns
import matplotlib.pyplot as plt

print('Bibliotecas carregadas com sucesso')
#Importando bibliotecas para o KNN
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from matplotlib.colors import ListedColormap
from sklearn.metrics import confusion_matrix
from sklearn import metrics
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, plot_roc_curve
print('Bibliotecas KNN carregadas com sucesso')

from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn import metrics
print('Bibliotecas MLP carregadas com sucesso')

"""Em seguida, os dados serão carregados do arquivo wine.csv e serão atribuidos nomes aos seus atributos. 

"""

# importa o arquivo e guarda em um dataframe do Pandas    sep=',', index_col=None
df_dataset = pd.read_csv( 'wine.csv', header=None) 
df_dataset.head(2)
df_dataset.columns = [  'Alcohol'
             	,'MalicAcid'
             	,'Ash'
            	,'Alcalinity of ash'
             	,'Magnesium'
            	,'Total Phenols'
             	,'Flavanoids'
             	,'NonFlavanoid Phenols'
             	,'Proanthocyanins'
            	,'Color Intensity'
             	,'Hue'
             	,'OD280_OD315'
             	,'Proline'
              ,'Name'
                ]

df_dataset.head(2)
print('Dados importados com sucesso!')

"""Agora, vamos dar uma olhada nas 100 primeiras amostras da base de dados.

> Bloco com recuo


"""

# exibe o dataframe
display(df_dataset.head(n=100))

"""A base de dados contém amostras de vinhos (linhas) representadas pelos seguintes atributos (colunas): `Alcohol`, `MalicAcid`,	`Ash`,	`Alcalinity of ash`,	`Magnesium`,	`Total Phenols`,	`Flavanoids`,	`NonFlavanoid Phenols`,	`Proanthocyanins`,	`Color Intensity`,	`Hue`,	`OD280_OD315`,	`Proline`. Por fim, temos o atributo `Name` que contém cada tipo de vinho.

O atributo `Name` é qualitativo, uma vez que é usado para identificar uma determinada amostra. Ele possui valores numéricos entre 1 a 3 e exerce apenas a função de identificação. 
O atributo `Name` é qualitativo nominal e representa tipos de vinhos. Portanto, o problema em questão é de <b>aprendizado supervisionado</b> $\rightarrow$ <b>classificação</b>.

## Pré-processamento: eliminação de atributos irrelevantes

O objetivo do problema é identificar diferentes tipos de vinhos (`Name`), dados os demais atributos. Assim, não foram removidos nenhuma coluna do banco de dados. 
"""

# remove as colunas id_planta e cidade_origem
#df_dataset = df_dataset.drop(columns=['Name'])

# imprime o dataframe
display(df_dataset.head(n=100))

"""## Pré-processamento: tratamento de atributos com valores ausentes

Outro passo importante, é verificar se existem atributos com valores ausentes (*NaN*) na base de dados.
"""

# índices das linhas que contém valores NaN
idxRowNan = pd.isnull(df_dataset).any(1).to_numpy().nonzero()

# imprime apenas as linhas com valoes ausentes
display(df_dataset.iloc[idxRowNan])

"""Como podemos ver, não existe o atributo com valores ausentes no banco de dados.  

Existem diversas técnicas para tratar atributos faltantes. Como este problema não possui valores ausentes, seu codigo foi comentado. Mas uma das tecnicas conhecidas seria a de preencher esses valores com a média dos valores conhecidos da respectiva classe.

def trataFaltantes( df_dataset ):
    '''
    Substitui os valores faltantes pela média dos outros valores do mesmo atributo
    de amostras que sejam da mesma classe    
    '''
    
    # seleciona apenas as linhas da base de dados onde a coluna largura_sepala não contém valores nulos
    notNull_ls = df_dataset.loc[ ~pd.isnull(df_dataset['largura_sepala']), :]
    notNull_cp = df_dataset.loc[ ~pd.isnull(df_dataset['comprimento_petala']), :]

    # calcula a media dos valores do atributo largura_sepala que não são nulos e que são da classe Iris-setosa 
    media_ls = notNull_ls[ notNull_ls['classe']=='Iris-setosa' ]['largura_sepala'].mean()
    media_cp = notNull_cp[ notNull_cp['classe']=='Iris-setosa' ]['comprimento_petala'].mean()

    # substitui os valores nulos pela média 
    df_dataset.loc[ pd.isnull(df_dataset['largura_sepala']), 'largura_sepala'] = media_ls
    df_dataset.loc[ pd.isnull(df_dataset['comprimento_petala']), 'comprimento_petala'] = media_cp
    
    return df_dataset

trataFaltantes( df_dataset )
    
# imprime apenas as linhas que antes possuiam valores NaN
print('\nAmostras que possuiam valores faltantes:')
display(df_dataset.iloc[idxRowNan])

## Pré-processamento: tratamento de dados inconsistentes ou redundantes

Outro passo importante, é verificar se existem dados inconsistentes ou redundantes. A forma mais comum de inconsistência é quando há amostras representadas por atributos com todos os valores iguais, mas com classes diferentes. A redundância é dada pela repetição de linhas na base de dados.

A seguir, vamos verificar se existem amostras duplicadas (redundantes) e inconsistentes.
"""

df_duplicates = df_dataset[ df_dataset.duplicated(subset=['Alcohol','MalicAcid','Ash','Alcalinity of ash','Magnesium','Total Phenols','Flavanoids','NonFlavanoid Phenols','Proanthocyanins','Color Intensity','Hue','OD280_OD315','Proline'],keep=False)]
# se houver valores redundantes ou inconsistentes, imprima 
if len(df_duplicates)>0:
    print('\nAmostras redundantes ou inconsistentes:')
    display(df_duplicates)
else:
    print('Não existem valores duplicados')

"""Como retornado pela função, não existe amostras redundantes (duplicadas) e  inconsistentes (amostras iguais, mas com classes distintas). 

Caso existissem, seriam removidas as amostras redundantes.
"""

def delDuplicatas( df_dataset ):
    '''
    Para cada grupo de amostras duplicadas, mantém uma e apaga as demais
    '''
    
    # remove as amostras duplicadas, mantendo apenas a primeira ocorrencia
    df_dataset = df_dataset.drop_duplicates(keep = 'first')    

    return df_dataset

df_dataset = delDuplicatas( df_dataset )

"""Agora é verificado se existem amostras inconsistentes. """

# para detectar inconsistências, a rotina abaixo obtém as amostras onde os valores 
# dos atributos continuam duplicados. Neste caso, os atributos serão iguais, mas as classes serão distintas
df_duplicates = df_dataset[ df_dataset.duplicated(subset=['Alcohol','MalicAcid','Ash','Alcalinity of ash','Magnesium','Total Phenols','Flavanoids','NonFlavanoid Phenols','Proanthocyanins','Color Intensity','Hue','OD280_OD315','Proline'],keep=False)] 

# se tiver valores inconsistentes, imprime 
if len(df_duplicates)>0:
    print('\nAmostras inconsistentes:')
    display(df_duplicates)
else:
    print('Não existem mostras inconsistentes')

"""Como retornado pela função, não existem inconsistentes. Caso existissem, seriam eliminadas."""

def delInconsistencias( df_dataset ):
    '''
    Remove todas as amostras inconsistentes da base de dados
    '''

    df_dataset = df_dataset.drop_duplicates(subset=['Alcohol','MalicAcid','Ash','Alcalinity of ash','Magnesium','Total Phenols','Flavanoids','NonFlavanoid Phenols','Proanthocyanins','Color Intensity','Hue','OD280_OD315','Proline'],keep=False)
  
    return df_dataset

df_dataset = delInconsistencias( df_dataset )

# obtém apenas as amostras onde os valores dos atributos estão duplicados
df_duplicates = df_dataset[ df_dataset.duplicated(subset=['Alcohol','MalicAcid','Ash','Alcalinity of ash','Magnesium','Total Phenols','Flavanoids','NonFlavanoid Phenols','Proanthocyanins','Color Intensity','Hue','OD280_OD315','Proline'],keep=False)] 

# se tiver valores redundantes ou inconsistentes, imprime 
if len(df_duplicates)>0:
    display(df_duplicates)
else:
    print('Não existem amostras redundantes ou inconsistentes')

"""# Algumas estatísticas sobre a base de dados.

A função `describe()` da `Pandas` sumariza as principais estatísticas sobre os dados de um *data frame*, como a média, o desvio padrão, valor máximo, valor mínimo e alguns percentis.
"""

# apresenta as principais estatísticas da base de dados
df_detalhes = df_dataset.describe()

display(df_detalhes)

"""## Pré-processamento: normalização dos atributos

Observe que a média do atributo `Proline` é bem superior a média dos outros atriburos. Diante disso, está claro que a escala dos atributos é diferente, o que pode prejudicar alguns métodos de aprendizado de máquina. Portanto, deve-se normalizar os valores dos atributos para que fiquem com média igual a zero e desvio padrão igual a um. Usando a biblioteca *scikit-learn*, é possível fazer a normalização usando a função [*sklearn.preprocessing.StandardScaler*](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Mas, para exercitar os conceitos aprendidos, foi criada uma função própria de normalização. 
"""

# Normalizando os dados
#sc = StandardScaler()
#X= df_dataset.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]].values
#print("1  ", X)
#X_train = sc.fit_transform(df_dataset.values)
#print("2  ", X_train)

def normalizar(X):
    """
    Normaliza os atributos em X
    
    Esta função retorna uma versao normalizada de X onde o valor da
    média de cada atributo é igual a 0 e desvio padrao é igual a 1. Trata-se de
    um importante passo de pré-processamento quando trabalha-se com 
    métodos de aprendizado de máquina.
    """
    
    m, n = X.shape # m = qtde de objetos e n = qtde de atributos por objeto
    
    # Incializa as variaves de saída
    X_norm = np.random.rand(m,n) # inicializa X_norm com valores aleatórios
    mu = 0 # inicializa a média
    sigma = 1 # inicializa o desvio padrão
     
    mu = np.mean(X, axis=0)
    sigma = np.std(X, axis=0, ddof=1)
    
    for i in range(m):
        X_norm[i,:] = (X[i,:]-mu) / sigma
        
    
    return X_norm, mu, sigma


# coloca os valores dos atributos na variável X
X = df_dataset.iloc[:,0:-1].values

# chama a função para normalizar X
X_norm, mu, sigma = normalizar(X)

df_dataset.iloc[:,0:13] = X_norm


#print("3", X_norm)

print('\nPrimeira amostra da base antes da normalização: [%2.4f %2.4f].' %(X[0,0],X[0,1]))
#print('\nApós a normalização, espera-se que a primeira amostra seja igual a: [-0.5747 0.1804].')
print('\nPrimeira amostra da base apos normalização: [%2.4f %2.4f].' %(X_norm[0,0],X_norm[0,1]))

"""Agora que os dados estão normalizados, analisa-se as informações estatísticas novamente."""

# apresenta as principais estatísticas da base de dados
df_detalhes = df_dataset.describe()

display(df_detalhes.round(8))

"""Pode-se ver acima que a média (*mean*) ficou igual a 0 e o desvio padrão (*std*) igual a 1. 

## Pré-processamento: detecção de *outliers*

Outro passo importante na análise e tratamento dos dados é a detecção de *outliers* (*i.e.*, dados gerados por leituras incorretas, erros de digitação, etc). 

Uma das maneiras mais simples de verificar se os dados contém *outliers* é criar um gráfico box plot de cada atributo. Para isso, podemos usar a função `boxplot` da biblioteca `Pandas`.
"""

# gera um bloxplot para cada atributo
df_dataset.boxplot(figsize=(15,7))
plt.show()

"""O box plot está indicando a presença de alguns atributos que possuem *outliers*, o que pode prejudicar o desempenho de vários métodos de aprendizado de máquina, pois tratam-se de amostras com valores de atributos incorretos. 

Outra forma de analisar se a base de dados contém *outliers* é usar gráficos de dispersão. Pode-se plotar gráficos de dispersão de todas as combinações de atributos da base de dados usando a função `scatter_matrix` da `Pandas`.
"""

pd.plotting.scatter_matrix(df_dataset, figsize=(18,18))

plt.show()

"""Outra forma de plotar gráficos de dispersão a partir dos _dataframes_ é usando a biblioteca `Seaborn`. Juntamente com essa biblioteca, também é recomendável importar a biblioteca `Matplotlib` para personalizar os gráficos. """

# matriz de gráficos scatter 
#hue='classe'
sns.pairplot(df_dataset, hue='Name', height=3.5);

# mostra o gráfico usando a função show() da matplotlib
plt.show()

"""
Pelos gráficos, os *outliers* parecem ser mais visíveis na combinação dos atributos `Color Intensity` e `Magnesium`. Então, vamos usar a função `lmplot` da biblioteca `Seaborn`para visualizar a combinação desses dois atributos."""

# define o scatter plot
sns.lmplot(x='Color Intensity', y='Magnesium', data=df_dataset, 
           #Alcalinity of ash	Magnesium
           fit_reg=False,  
           hue='Name')

# cria um título para o gráfico
plt.title('Flavanoids vs Hue')

# mostra o gráfico
plt.show()

"""Pelos gráficos vistos até o momento, fica claro que um dos *outliers* possui um alto valor no atributo `Color Intensity`. Já o segundo outlier contém um alto valor no atributo `Magnesium`. 

A bilioteca `Seaborn` permite criar gráficos boxplot agrupados por um determinado atributo, o que facilita a análise dos dados. No exemplo abaixo, criaremos boxplots para cada atributo agrupados pela classe.
"""

for atributo in df_dataset.columns[:-1]:
    # define a dimensão do gráfico
    plt.figure(figsize=(8,8))

    # cria o boxplot
    sns.boxplot(x="Name", y=atributo, data=df_dataset, whis=1.5)

    # mostra o gráfico
    plt.show()

"""Os box plots dos atributos mostraram outros *outliers* que não haviam aparecido no primeiro box plot. Portanto, esses novos valores são considerados *outliers* se analisarmos as classes individualmente, mas não são considerados *outliers* se analisarmos a base de dados de forma geral. 

Outro tipo de gráfico que ajuda a detectar *outliers* é o histograma. Portanto, será usado para analisar cada atributo.
"""

for atributo in df_dataset.columns[:-1]:
    
    # cria o histograma
    n, bins, patches = plt.hist(df_dataset[atributo].values,bins=10, color='red', edgecolor='black', linewidth=0.9)

    # cria um título para o gráfico
    plt.title(atributo)

    # mostra o gráfico
    plt.show()

"""Agora, pode-se usar um gráfico de densidade para fazer o mesmo tipo de análise."""

for atributo in df_dataset.columns[:-1]:

    # criando o gráfico de densidade para cada atributo
    densityplot = df_dataset[atributo].plot(kind='density')
    
    # cria um título para o gráfico
    plt.title(atributo)

    # mostra o gráfico
    plt.show()

"""Uma das maneiras mais simples de tratar *outliers* é remover aqueles valores que são menores que $Q1 - 1.5 * IQR$ ou maiores que $Q3 + 1.5 * IQR$, onde $Q1$ é o primeiro quartil, $Q3$ é o terceiro quartil e $IQR$ é o intervalo interquartil. O IQR pode ser calculado pela seguinte equação: $IQR = Q3-Q1$. 

Com base nessas informações, vamos usar a função abaixo para remover os *outliers* da base de dados. Usaremos como base o IQR de cada atributo em relação a todos os valores na base de dados, em vez do IQR individual de cada classe.
"""

def removeOutliers(df_dataset):
    """
    Remove os outliers da base de dados 
    """
    
    for atributo in df_dataset.columns[:-1]:

        # obtem o terceiro e o primeiro quartil. 
        q75, q25 = np.percentile(df_dataset[atributo].values, [75 ,25])
        
        # calcula o IQR
        IQR = q75 - q25

        # remove os outliers com base no valor do IQR
        df_dataset = df_dataset[ (df_dataset[atributo]<=(q75+1.5*IQR)) & (df_dataset[atributo]>=(q25-1.5*IQR)) ]
    
    return df_dataset

# remove os outliers
df_dataset = removeOutliers( df_dataset )

# apresenta as principais estatísticas sobre a base de dados
df_dataset.boxplot(figsize=(15,7))
plt.show()

# matriz de gráficos scatter 
sns.pairplot(df_dataset, hue='Name', height=3.5);

# mostra o gráfico usando a função show() da matplotlib
plt.show()

"""Depois da remoção, o box plot e os gráficos de dispersão indicam que não há mais nenhum *outlier* na base de dados. 

Com os novos gráficos de dispersão, também é possível perceber que no atributo *Flavanoids* e *Alcohol é  mais fácil de identificar as classes, pois está mais separada no espaço de atributos. Por outro lado, em várias combinações de atributos, as classes **1**, **2** e **3** se misturam.

**IMPORTANTE:** antes de realizar a remoção de *outliers*, é mandatório analisar cuidadosamente as características das amostras antes de removê-las. Em alguns casos, remover os *outliers* pode ser prejudicial. Além disso, algumas tarefas de aprendizado de máquina são voltadas para a detecção de *outliers* e, portanto, esses dados não podem ser removidos. Adicionalmente, se a base de dados for desbalanceada, a remoção dos *outliers* com base nas estatísticas de toda a base, pode acabar removendo amostras da classe minoritária (aquela que possui menos amostras). Ainda, alguns métodos de classificação, tais como métodos baseados em *ensemble* e métodos baseados em árvores, costumam ser robustos a *outliers*. Diante disso, em alguns problemas, é recomendável remover apenas aqueles *outliers* que são claramente erros de leitura/digitação, isto é, valores que estão fora dos limites aceitáveis para o que é esperado para um determinado atributo (por exemplo, uma pessoa com 500 anos ou um bebê com 300 kg). 

## Pré-processamento: distribuição das classes

Outro passo importante na análise de dados é verificar a distribuição das classes. Para isso, é possível criar um gráfico de barra indicando quantas amostras de cada classe há na base de dados.
"""

display( df_dataset['Name'].value_counts() )

# cria um gráfico de barras com a frequência de cada classe
sns.countplot(x="Name", data=df_dataset)

# mostra o gráfico
plt.show()

"""Pode-se ver que as classes são balanceadas. Se o número de exemplos em alguma das classes fosse muito superior às demais, seria necessário que usar alguma técnica de balanceamento de classes, pois o modelo gerado pela maioira dos métodos de aprendizado supervisionado costuma ser tendencioso para as classes com maior número de amostras.

## Pré-processamento: correlação entre os atributos

Quando dois atributos possuem valores idênticos ou muito semelhantes para todas as amostras, um deles deve ser eliminado ou eles devem ser combinados. Isso ajuda a diminuir o custo computacional das tarefas de aprendizado e evita que o aprendizado de alguns método seja prejudicado, principalmente os métodos baseados em otimização.

Uma das maneiras mais comuns de analisar a correlação dos dados é através das matrizes de correlação e covariância. Pode-se fazer isso usando a biblioteca `Numpy` ou a `Pandas`.

Primeiro, será usatilizada a `Numpy`.
"""

# criando uma matriz X com os valores do data frame
X = df_dataset.iloc[:,:-1].values

# matriz de covariancia
covariance = np.cov(X, rowvar=False)

# matriz de correlação
correlation = np.corrcoef(X, rowvar=False)

print('Matriz de covariância: ')
display(covariance)

print('\n\nMatriz de correlação: ')
display(correlation)

"""Agora, serão calculadas as matrizes de correlação e covariância usando a `Pandas`."""

# matriz de covariancia
df_covariance = df_dataset.cov()

# matriz de correlação
df_correlation = df_dataset.corr()

print('Matriz de covariância: ')
display(df_covariance)

print('\n\nMatriz de correlação: ')
display(df_correlation)

"""Pode-se ver que os atributos `Total Phenols` e `Flavanoids` possuem alta covariância e alta correlação. Se o problema em questão tivesse muitos atributos, podería-se pensar na possibilidade de combinar esses dois atributos. Se a correlação entre dois atributos for igual a 1 ou -1, significa que eles são redundantes e um deles poderia ser eliminado.

Para facilitar a visualização, será plotada a matriz de covariância e a de correlação usando mapas de cores.
"""

# cria um mapa de cores dos valores da covariancia
sns.heatmap(df_covariance, 
        xticklabels=df_correlation.columns,
        yticklabels=df_correlation.columns)

plt.title('Covariancia')
plt.show()

# cria um mapa de cores dos valores da correlação
sns.heatmap(df_correlation, 
        xticklabels=df_correlation.columns,
        yticklabels=df_correlation.columns)

plt.title('Correlacao')
plt.show()

"""k-Nearest Neighbors (KNN), esse algorritimo tenta classificar cada amostra de um conjunto de dados avaliando sua distância em relação aos vizinhos mais próximos. Se os vizinhos mais próximos forem majoritariamente de uma classe, a amostra em questão será classificada nesta categoria, como classe nesse banco de dados temos o `Name`. Como atributos descritivos temos: `Alcohol`, `MalicAcid`,	`Ash`,	`Alcalinity of ash`,	`Magnesium`,	`Total Phenols`,	`Flavanoids`,	`NonFlavanoid Phenols`,	`Proanthocyanins`,	`Color Intensity`,	`Hue`,	`OD280_OD315`,	`Proline`."""

# Definindo as colunas como atributos descritivos
X = df_dataset.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]].values
# Definindo a coluna 13 como atributo Classe (Name)
y = df_dataset.iloc[:, 13].values

# Separando o conjunto de dados em conjunto de treinamento e deteste sendo 70% treinamento 30% teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) 
# Gerando o Classificador com os dados de treinamento
classifier = KNeighborsClassifier(n_neighbors = 17)
classifier.fit(X_train, y_train)

# Realizando a Predição das Classes dos dados do conjunto de teste 
y_pred = classifier.predict(X_test)

# Gerando a Matriz de Confusão com os dados de teste
cm = confusion_matrix(y_test, y_pred)
# Precissão do modelo de acuriacia
print("Acuracia:",metrics.accuracy_score(y_test, y_pred))

# Vizualização dos Resultados sobre o Conjunto de Treinamento
print(classification_report(y_test,y_pred))

#vizualizando matriz de confusão
print("Matriz de confusão")
print(cm)
#criando matriz de confusão
fig, (ax1) = plt.subplots(1, figsize=(10,4))
 
sns.heatmap(cm, annot=True, fmt="d",  cmap="Spectral")
 
ax1.set_title("Matriz Confunsão")

 
axs = [ax1]
 
for ax in axs:
    ax.set(xlabel='Previsto', ylabel='Real')
plt.show()

#hitmap da matriz de acuracia
# '''Uso da biblioteca Matplotlib
#X_set, y_set = X_train, y_train
#X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
#                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
#plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
#             alpha = 0.75, cmap = ListedColormap(('cyan', 'gray')))
#plt.xlim(X1.min(), X1.max())
#plt.ylim(X2.min(), X2.max())
#for i, j in enumerate(np.unique(y_set)):
#    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
#                c = ListedColormap(('red', 'green'))(i), label = j)
#plt.title('Classificador KNN (Dados Treinamento)')
#plt.xlabel('Idade')
#plt.ylabel('Salário')
#plt.legend()
#plt.show()'''

"""Agora será utilizado um algoritimo para encontrar a melhor correspondencia de K e assim obter a melhor Acuracia.
Ele testa valores até obter a melhor correspondencia.
"""

k = range(1,50,2)
testing_accuracy = []
training_accuracy = []
score = 0

for i in k:
    knn = KNeighborsClassifier(n_neighbors = i)
    pipe_knn = Pipeline([('scale', MinMaxScaler()), ('knn', knn)])
    pipe_knn.fit(X_train, y_train)
    
    y_pred_train = pipe_knn.predict(X_train)
    training_accuracy.append(accuracy_score(y_train, y_pred_train))
    
    y_pred_test = pipe_knn.predict(X_test)
    acc_score = accuracy_score(y_test,y_pred_test)
    testing_accuracy.append(acc_score)
    
    if score < acc_score:
        score = acc_score
        best_k = i
        
print('Melhor acuracia encontrada', score, 'Melhor ocorrencia de K', best_k)
print(classification_report(y_test,y_pred))

# Definindo as colunas como atributos descritivos
X = df_dataset.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]].values
# Definindo a coluna 13 como atributo Classe (Name)
y = df_dataset.iloc[:, 13].values

# Separando o conjunto de dados em conjunto de treinamento e deteste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) #70% treinamento 30% teste
# Gerando o Classificador com os dados de treinamento
classifier = KNeighborsClassifier(n_neighbors = 7)
classifier.fit(X_train, y_train)

# Realizando a Predição das Classes dos dados do conjunto de teste 
y_pred = classifier.predict(X_test)

# Gerando a Matriz de Confusão com os dados de teste
cm = confusion_matrix(y_test, y_pred)
# Precissão do modelo de acuriacia
print("Acuracia:",metrics.accuracy_score(y_test, y_pred))

# Vizualização dos Resultados sobre o Conjunto de Treinamento
print('Atualizando:',classification_report(y_test,y_pred))

#vizualizando matriz de confusão
#print("Matriz de confusão")
#print(cm)
display(cm)
#criando matriz de confusão
fig, (ax1) = plt.subplots(1, figsize=(10,4))
 
sns.heatmap(cm, annot=True, fmt="d",  cmap="Spectral")
 
ax1.set_title("Matriz Confunsão")

 
axs = [ax1]
 
for ax in axs:
    ax.set(xlabel='Previsto', ylabel='Real')
plt.show()

sns.lineplot(k, testing_accuracy)
sns.lineplot(k, testing_accuracy)

sns.lineplot(k, training_accuracy)
sns.lineplot(k, training_accuracy)
plt.legend(['testing accuracy', 'training accuracy'])

"""MLP Perceptron Multicamadas (PMC ou MLP — Multi Layer Perceptron) é uma rede neural com uma ou mais camadas ocultas com um número indeterminado de neurônios. 
MLP (Multi Layer Perceptron) – Modelo de aprendizado supervisionado onde foi fornecido uma amostra de dados informando a classificação dos mesmos, assim treinando o modelo para que quando uma nova amostra for recebida o mesmo seja capaz de estabelecer a que grupo uma amostra pertence. Usando os dados de 
treino o modelo alcançou uma taxa sempre superior a 90% de acurácia para o algoritmo de treinamento *`sgd`* para os dados de treino e teste com número de neurônios = 15. Assim, foi realizada a substituição para o algoritmo *`lbfgs`* ao qual foi obtido uma taxa de 100% (1) de acerto na classificação. Também foi observado que a quantidade de neurônios influência diretamente na precisão do modelo onde ao realiza testes com 1 neurônio o algoritmo com treino *`lbfgs`* teve uma taxa de acurácia inferior a 90% e com 2 neurônios 100%. Já o método de treino *`sgd`* mesmo com 10000 neurônios não conseguiu obter 100% de acurácia.


"""

#organizando em entrada e saidas
x = df_dataset.iloc[:,0:12].values # Todos os dados da segunda ate a ultima coluna
y = df_dataset.iloc[:,13].values # Todos os dados da primeira coluna do dataset

#dividir em treinamento 70% para dos dados e 30% para testes
X_train, X_test, y_train, y_test =  train_test_split(X,y,test_size = 0.30, random_state= 0) #random_state é uma semente para gerar valores aleatorios

#Treinando o Modelo

neuronios = 2 #quanto menor o número do neoronios menor a acc(accuracy)
Ativacao = 'identity'
#sgd
algoTreinamento = 'lbfgs'
Aprendizado = 0.001 #representa aquantidade de saltos até chegar no objetivo (não é um valor exato)
resultado = MLPClassifier(hidden_layer_sizes=neuronios,  activation=Ativacao, solver=algoTreinamento, learning_rate_init=Aprendizado )

#Treinando
resultado.fit(X,y)
resultado.classes_
y_pred = resultado.predict(X_train)
acc = metrics.accuracy_score(y_train, y_pred)
print("Resultado teino de acuracia:",acc)
#Testando os dados


y_pred = resultado.predict(X_test)
print("Resultado teste de acuracia:",acc)

# Gerando a Matriz de Confusão com os dados de teste
cm = confusion_matrix(y_test, y_pred)

#vizualizando matriz de confusão
#print("Matriz de confusão")
#print(cm)

#criando matriz de confusão
fig, (ax1) = plt.subplots(1, figsize=(10,4))
 
sns.heatmap(cm, annot=True, fmt="d",  cmap="Spectral")
 
ax1.set_title("Matriz Confunsão")

 
axs = [ax1]
 
for ax in axs:
    ax.set(xlabel='Previsto', ylabel='Real')
plt.show()

"""---
## Conclusão

Foram mostradas as principais etapas de visualização, interpretação e pré-processamento dos dados. Foi apresentado como  eliminar atributos  irrelevantes e tratar dados faltantes, redundantes ou inconsistentes. Além disso, foi mostrado como deve ser feita a normalização dos dados e quais os possíveis impactos dessa etapa no desempenho dos métodos de aprendizado. Ainda, foi mostrada uma das técnicas de remoção de outliers, como visualizar a distribuição das classes e como analisar a correlação dos atributos.
Tambem foram apresentados os dados de acuracia para o algoritimo de KNN e o de MLP. No algoritimo KNN foi utilizado uma função para encontrar a melhor correspondencia de K, assim o valor da acuracia chegoa 1 (100%). Já no MLP, a primeiro momento foi utilizado o `sgd` como algoritimo de teinamento, e mesmo com uma alta quantidade de neuronios ele não obteve uma acuracia em 1 (100%); ao substituilo pelo algoritimo de treinamento `lbfgs`, com apenas 2 neuronios ele já obteve uma acuracia de 1 (100%). Assim, Tanto KNN quanto o MLP conseguiram obter a excelencia na classificação do banco de dados `wine.csv`.

---
## Referências

[1] R. A. Fisher. The use of multiple measurements in taxonomic problems. Annual Eugenics, 7, Part II, 179-188 (1936). DOI: [10.1111/j.1469-1809.1936.tb02137.x](http://dx.doi.org/10.1111/j.1469-1809.1936.tb02137.x).

[2] A. C. P. L. F. de Carvalho, et al. Inteligência Artificial - Uma Abordagem de Aprendizado de Máquina, 2a Edição, Rio de Janeiro, LTC, 2022.

Classificação de variedades de vinho. Kaggle, VANESSA ALINE 2019. Disponível em: <https://www.kaggle.com/code/vanessaaline/mlp-wine>. Acesso em: 22 de outubro. de 2022.

Entendendo a regressão e classicação knn do zero. Flavio Figueiredo, 2022. Disponível em: <https://icd-ufmg.github.io/20-knn/>. Acesso em: 22 de outubro. de 2022.

Previsão KNN para a qualidade do vinho tinto. Kaggle, ADITIANI, 2020. Disponível em: <https://www.kaggle.com/code/aditiani/knn-prediction-for-red-wine-quality>. Acesso em: 22 de outubro. de 2022.


Classificação KNN usando Scikit-Learn em Python. Codespeedy, Snigdha Ranjith. Disponível em: <https://www.kaggle.com/code/aditiani/knn-prediction-for-red-wine-quality>. Acesso em: 22 de outubro. de 2022.

Machine Learning: observe como a KNN funciona prevendo as variedades dos vinhos italianos. Codespeedy, Papa Moryba Kouate, 2020. Disponível em: <https://towardsdatascience.com/machine-learning-observe-how-knn-works-by-predicting-the-varieties-of-italian-wines-a64960bb2dae>. Acesso em: 22 de outubro. de 2022.
 
Tutorial de classificação KNN usando Scikit-learnKNN Classification Tutorial using Scikit-learn. Codespeedy, Avinash Navlani, 2018. Disponível em: <https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learnrdl>. Acesso em: 22 de outubro. de 2022.

---
"""

